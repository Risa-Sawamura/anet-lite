# examples/quickstart.py
from anet_lite import theta_consistency, entropy_rate, processivity, f_total, two_second_precursor

# ダミーデータ（本番では学習ループのlossやgradノルムを渡す）
loss  = [0.9, 0.8, 0.7, 0.75, 0.9, 1.1, 1.4]
gnorm = [1.0, 0.9, 1.1, 1.2, 1.3, 1.4, 1.6]
snorm = [0.9, 1.0, 1.0, 1.1, 1.2, 1.3, 1.5]
noise = [0.05, 0.06, 0.05, 0.07, 0.1, 0.15, 0.2]
ref   = [0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05]

phi = theta_consistency(noise, ref)                  # 一致度ϑ
s   = entropy_rate(loss)                             # エントロピー変化Ṡ
p   = processivity(gnorm, snorm)                     # プロセシビティP
F   = f_total(s, p, w_s=0.7, w_p=0.3)                # 総合スコアF_Total
alert, z = two_second_precursor(loss, rate_hz=5)     # 2秒前駆

print(f"θ={phi:.3f}, Ṡ={s:.3f}, P={p:.3f}, F={F:.3f}, precursor={alert}, z={z:.2f}")
```

---

### 実行方法

```bash
python examples/quickstart.py
